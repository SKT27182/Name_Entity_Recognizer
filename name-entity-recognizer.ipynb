{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# imports","metadata":{}},{"cell_type":"code","source":"import sys\nimport os\n\nimport pandas as pd\nimport numpy as np\n\n\n# Getting the environment where this notebook is running\nif 'KAGGLE_URL_BASE' in os.environ:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    HUGGINGFACE_API_KEY = user_secrets.get_secret(\"HUGGINGFACE_API_KEY\")\nelif 'google.colab' in sys.modules:\n    !pip -q install python-dotenv\n    from dotenv import load_dotenv\n    load_dotenv()\n    HUGGINGFACE_API_KEY = os.getenv('HUGGINGFACE_API_KEY')\n\nelse:\n    from dotenv import load_dotenv\n    load_dotenv()\n    HUGGINGFACE_API_KEY = os.getenv('HUGGINGFACE_API_KEY')","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:01:47.049298Z","iopub.execute_input":"2024-01-22T18:01:47.049682Z","iopub.status.idle":"2024-01-22T18:01:47.552681Z","shell.execute_reply.started":"2024-01-22T18:01:47.049649Z","shell.execute_reply":"2024-01-22T18:01:47.551773Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q --upgrade datasets\n\n!pip install -q transformers evaluate seqeval\n\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:01:49.056130Z","iopub.execute_input":"2024-01-22T18:01:49.057666Z","iopub.status.idle":"2024-01-22T18:02:25.101308Z","shell.execute_reply.started":"2024-01-22T18:01:49.057630Z","shell.execute_reply":"2024-01-22T18:02:25.100347Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ns3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# HuggingFace Login","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nfrom huggingface_hub import login\nlogin(token=HUGGINGFACE_API_KEY, write_permission=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:25.103360Z","iopub.execute_input":"2024-01-22T18:02:25.103865Z","iopub.status.idle":"2024-01-22T18:02:25.199849Z","shell.execute_reply.started":"2024-01-22T18:02:25.103836Z","shell.execute_reply":"2024-01-22T18:02:25.198885Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Loading dataset","metadata":{}},{"cell_type":"code","source":"ner_data = load_dataset(\"SKT27182/NER_processed_data\")","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:25.201119Z","iopub.execute_input":"2024-01-22T18:02:25.201458Z","iopub.status.idle":"2024-01-22T18:02:27.432246Z","shell.execute_reply.started":"2024-01-22T18:02:25.201423Z","shell.execute_reply":"2024-01-22T18:02:27.431233Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/627 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"192a827e9db04730ba0887747fc2098f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.25M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f54bda7dd85749b9aca117aa32c30ded"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/569k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df50fa33f66f43c7968e02e915afd6df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/15766 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"017f065ccbfc41c58ed3b973ca4612da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3943 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52b88ae6e74a4c5080de26fcbdb3f06a"}},"metadata":{}}]},{"cell_type":"code","source":"ner_data","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:27.434703Z","iopub.execute_input":"2024-01-22T18:02:27.435009Z","iopub.status.idle":"2024-01-22T18:02:27.442369Z","shell.execute_reply.started":"2024-01-22T18:02:27.434983Z","shell.execute_reply":"2024-01-22T18:02:27.441343Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tags', 'text', 'dataset_num', 'tokens', 'ner_tags'],\n        num_rows: 15766\n    })\n    test: Dataset({\n        features: ['id', 'tags', 'text', 'dataset_num', 'tokens', 'ner_tags'],\n        num_rows: 3943\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"markdown","source":"- Using distilber for fine-tuning","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:27.443928Z","iopub.execute_input":"2024-01-22T18:02:27.444219Z","iopub.status.idle":"2024-01-22T18:02:32.917997Z","shell.execute_reply.started":"2024-01-22T18:02:27.444194Z","shell.execute_reply":"2024-01-22T18:02:32.916917Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5684d64e59c4c32a1623d4da324b688"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4fc7acca706489fb1fafc71df0ebcb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5222793cb29840b0aa7530e5969b41d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ba1aafc7b0c4fb3a3b435680e89e1ec"}},"metadata":{}}]},{"cell_type":"markdown","source":"- After tokenizing there comes few extra tokens, plus few words get splitted to one or more sub-words. So tokenizing them as -100, So it will be ignored in loss.","metadata":{}},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n\n    labels = []\n    for i, label in enumerate(examples[f\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:  # Set the special tokens to -100.\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n                label_ids.append(label[word_idx])\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:32.919488Z","iopub.execute_input":"2024-01-22T18:02:32.920020Z","iopub.status.idle":"2024-01-22T18:02:32.927695Z","shell.execute_reply.started":"2024-01-22T18:02:32.919991Z","shell.execute_reply":"2024-01-22T18:02:32.926701Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenized_ner = ner_data.map(tokenize_and_align_labels, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:32.929331Z","iopub.execute_input":"2024-01-22T18:02:32.930060Z","iopub.status.idle":"2024-01-22T18:02:36.224805Z","shell.execute_reply.started":"2024-01-22T18:02:32.930023Z","shell.execute_reply":"2024-01-22T18:02:36.223784Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15766 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fb7a17386534fbc9dfceb72ec8869d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3943 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ef93a0bfbf84f67a57b4a0553539b03"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_ner","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:36.226049Z","iopub.execute_input":"2024-01-22T18:02:36.226352Z","iopub.status.idle":"2024-01-22T18:02:36.233125Z","shell.execute_reply.started":"2024-01-22T18:02:36.226325Z","shell.execute_reply":"2024-01-22T18:02:36.231849Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tags', 'text', 'dataset_num', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 15766\n    })\n    test: Dataset({\n        features: ['id', 'tags', 'text', 'dataset_num', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 3943\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:36.234479Z","iopub.execute_input":"2024-01-22T18:02:36.234823Z","iopub.status.idle":"2024-01-22T18:02:47.653350Z","shell.execute_reply.started":"2024-01-22T18:02:36.234796Z","shell.execute_reply":"2024-01-22T18:02:47.652449Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\nseqeval = evaluate.load(\"seqeval\")","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:47.658014Z","iopub.execute_input":"2024-01-22T18:02:47.658634Z","iopub.status.idle":"2024-01-22T18:02:50.192374Z","shell.execute_reply.started":"2024-01-22T18:02:47.658602Z","shell.execute_reply":"2024-01-22T18:02:50.191543Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b8b50a9b2bf45958437c9389f4233ef"}},"metadata":{}}]},{"cell_type":"code","source":"label_list = [\"O\", \"treatment\", \"chronic_disease\", \"cancer\", \"allergy_name\"]","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:50.193899Z","iopub.execute_input":"2024-01-22T18:02:50.194181Z","iopub.status.idle":"2024-01-22T18:02:50.199058Z","shell.execute_reply.started":"2024-01-22T18:02:50.194157Z","shell.execute_reply":"2024-01-22T18:02:50.197926Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"example = ner_data[\"train\"][0]\nlabels = [label_list[int(i)] for i in example[f\"ner_tags\"]]\nlabels","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:50.200678Z","iopub.execute_input":"2024-01-22T18:02:50.201104Z","iopub.status.idle":"2024-01-22T18:02:50.235271Z","shell.execute_reply.started":"2024-01-22T18:02:50.201065Z","shell.execute_reply":"2024-01-22T18:02:50.234117Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['O', 'O', 'O', 'cancer', 'cancer']"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# labels = [label_list[int(i)] for i in ner_[f\"ner_tags\"]]\n\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    true_predictions = [\n        [label_list[int(p)] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    true_labels = [\n        [label_list[int(l)] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:50.236623Z","iopub.execute_input":"2024-01-22T18:02:50.236965Z","iopub.status.idle":"2024-01-22T18:02:50.256100Z","shell.execute_reply.started":"2024-01-22T18:02:50.236936Z","shell.execute_reply":"2024-01-22T18:02:50.254978Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# compute_metrics(())","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:50.257510Z","iopub.execute_input":"2024-01-22T18:02:50.257975Z","iopub.status.idle":"2024-01-22T18:02:50.277354Z","shell.execute_reply.started":"2024-01-22T18:02:50.257934Z","shell.execute_reply":"2024-01-22T18:02:50.276007Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Fine-Tuning","metadata":{}},{"cell_type":"code","source":"id2label = {\n    0.0: \"O\",\n    1.0: \"treatement\",\n    2.0: \"chronic_disease\",\n    3.0: \"cancer\",\n    4.0: \"allergy_name\",\n}\nlabel2id = {\n    \"O\": 0.0,\n    \"treatement\": 1.0,\n    \"chronic_disease\": 2.0,\n    \"cancer\": 3.0,\n    \"allergy_name\": 4.0,\n}","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:50.278844Z","iopub.execute_input":"2024-01-22T18:02:50.279669Z","iopub.status.idle":"2024-01-22T18:02:50.300195Z","shell.execute_reply.started":"2024-01-22T18:02:50.279624Z","shell.execute_reply":"2024-01-22T18:02:50.299092Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    \"distilbert-base-uncased\", num_labels=5, id2label=id2label, label2id=label2id\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:50.301646Z","iopub.execute_input":"2024-01-22T18:02:50.302001Z","iopub.status.idle":"2024-01-22T18:02:52.587912Z","shell.execute_reply.started":"2024-01-22T18:02:50.301970Z","shell.execute_reply":"2024-01-22T18:02:52.586987Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"393600da7434426d951afaa95e850cda"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Trainer","metadata":{"execution":{"iopub.status.busy":"2024-01-21T08:54:59.448081Z","iopub.execute_input":"2024-01-21T08:54:59.448444Z","iopub.status.idle":"2024-01-21T08:54:59.453857Z","shell.execute_reply.started":"2024-01-21T08:54:59.448415Z","shell.execute_reply":"2024-01-21T08:54:59.452771Z"}}},{"cell_type":"code","source":"def continual_training(model, train_data, test_data, output_dir, push_to_hub=True):\n    \n    training_args = TrainingArguments(\n    output_dir=f\"Name_Entity_Recognizer_model{output_dir}\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    push_to_hub=push_to_hub,\n)\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_data,\n        eval_dataset=test_data,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics,\n    )\n    \n\n    trainer.train()\n    \n    return trainer.model\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:52.589190Z","iopub.execute_input":"2024-01-22T18:02:52.589494Z","iopub.status.idle":"2024-01-22T18:02:52.597173Z","shell.execute_reply.started":"2024-01-22T18:02:52.589467Z","shell.execute_reply":"2024-01-22T18:02:52.595958Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Task-1","metadata":{}},{"cell_type":"code","source":"part_one_data = tokenized_ner.filter(lambda example: example['dataset_num'] == 1)\ntuned_model1 = continual_training(model, part_one_data[\"train\"], part_one_data[\"test\"], output_dir=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:02:52.598843Z","iopub.execute_input":"2024-01-22T18:02:52.599687Z","iopub.status.idle":"2024-01-22T18:08:28.396703Z","shell.execute_reply.started":"2024-01-22T18:02:52.599648Z","shell.execute_reply":"2024-01-22T18:08:28.395490Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/15766 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d381583bc014b2c87e2a5429cb518d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/3943 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d4348230d6044908c3e48219b6929de"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240122_180641-3oyolv3w</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/skt27182/huggingface/runs/3oyolv3w' target=\"_blank\">wandering-planet-44</a></strong> to <a href='https://wandb.ai/skt27182/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/skt27182/huggingface' target=\"_blank\">https://wandb.ai/skt27182/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/skt27182/huggingface/runs/3oyolv3w' target=\"_blank\">https://wandb.ai/skt27182/huggingface/runs/3oyolv3w</a>"},"metadata":{}},{"name":"stderr","text":"You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='724' max='724' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [724/724 01:03, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.249577</td>\n      <td>0.644429</td>\n      <td>0.693924</td>\n      <td>0.668261</td>\n      <td>0.917317</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.301800</td>\n      <td>0.233202</td>\n      <td>0.665049</td>\n      <td>0.732900</td>\n      <td>0.697328</td>\n      <td>0.923742</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: chronic_disease seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: cancer seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: treatment seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: allergy_name seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: chronic_disease seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: cancer seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: treatment seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: allergy_name seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Task-2","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset, concatenate_datasets\n\npart_two_data = tokenized_ner.filter(lambda example: example['dataset_num'] == 2)\n\n# Include only 100 examples from dataset_num=1\npart_one_data_subset = part_one_data[\"train\"][:100]\n\n# Convert the dictionary to a dataset\npart_one_data_subset = Dataset.from_dict(part_one_data_subset)\n\n# Concatenate the examples from dataset_num=2 and the subset from dataset_num=1\npart_two_data_train = concatenate_datasets([part_two_data[\"train\"], part_one_data_subset])\n\n# Continue training the model with the combined dataset\ntuned_model2 = continual_training(tuned_model1, \n                                  part_two_data_train, \n                                  concatenate_datasets([part_two_data[\"test\"], part_one_data[\"test\"]]), \n                                  output_dir=2)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:09:25.791490Z","iopub.execute_input":"2024-01-22T18:09:25.792483Z","iopub.status.idle":"2024-01-22T18:10:42.487245Z","shell.execute_reply.started":"2024-01-22T18:09:25.792436Z","shell.execute_reply":"2024-01-22T18:10:42.486096Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='648' max='648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [648/648 01:04, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.222619</td>\n      <td>0.683535</td>\n      <td>0.734871</td>\n      <td>0.708274</td>\n      <td>0.924117</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.243600</td>\n      <td>0.220950</td>\n      <td>0.679740</td>\n      <td>0.741376</td>\n      <td>0.709221</td>\n      <td>0.924853</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: treatment seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: cancer seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: chronic_disease seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: allergy_name seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: treatment seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: cancer seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: chronic_disease seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: allergy_name seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Task-3","metadata":{}},{"cell_type":"code","source":"part_three_data = tokenized_ner.filter(lambda example: example['dataset_num'] == 3)\n\n# Include only 100 examples from dataset_num=1,2\npart_one_data_subset = part_one_data[\"train\"][:50]\npart_two_data_subset = part_two_data[\"train\"][:50]\n\n# Convert the dictionary to a dataset\npart_one_data_subset = Dataset.from_dict(part_one_data_subset)\npart_two_data_subset = Dataset.from_dict(part_two_data_subset)\n\n# Concatenate the examples from dataset_num=2 and the subset from dataset_num=1\npart_three_data_train = concatenate_datasets([part_three_data[\"train\"], part_one_data_subset, part_two_data_subset])\n\n# Continue training the model with the combined dataset\ntuned_model3 = continual_training(tuned_model2, \n                                  part_three_data_train, \n                                  concatenate_datasets([part_three_data[\"test\"], part_two_data[\"test\"], part_one_data[\"test\"]]),\n                                 output_dir=3)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:10:42.489437Z","iopub.execute_input":"2024-01-22T18:10:42.489860Z","iopub.status.idle":"2024-01-22T18:12:01.985004Z","shell.execute_reply.started":"2024-01-22T18:10:42.489823Z","shell.execute_reply":"2024-01-22T18:12:01.983369Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/15766 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"235796da2eaa40bbafe7e595a7b644d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/3943 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81dea1aaaa4e48adb0147bed1c32f560"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='628' max='628' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [628/628 01:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.208426</td>\n      <td>0.693394</td>\n      <td>0.747595</td>\n      <td>0.719475</td>\n      <td>0.926649</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.228000</td>\n      <td>0.212323</td>\n      <td>0.690033</td>\n      <td>0.757616</td>\n      <td>0.722247</td>\n      <td>0.926519</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: treatment seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: cancer seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: chronic_disease seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: allergy_name seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: treatment seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: cancer seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: chronic_disease seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: allergy_name seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task-4 (Combined dataset)","metadata":{}},{"cell_type":"code","source":"combined_training = continual_training(model, \n                                       tokenized_ner[\"train\"], \n                                       tokenized_ner[\"test\"], \n                                       push_to_hub=True,\n                                      output_dir=\"\")","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:12:01.986970Z","iopub.execute_input":"2024-01-22T18:12:01.987288Z","iopub.status.idle":"2024-01-22T18:15:02.620437Z","shell.execute_reply.started":"2024-01-22T18:12:01.987261Z","shell.execute_reply":"2024-01-22T18:15:02.619222Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1972' max='1972' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1972/1972 02:47, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.208700</td>\n      <td>0.205802</td>\n      <td>0.708297</td>\n      <td>0.767638</td>\n      <td>0.736775</td>\n      <td>0.930662</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.154700</td>\n      <td>0.205588</td>\n      <td>0.717994</td>\n      <td>0.765099</td>\n      <td>0.740798</td>\n      <td>0.931151</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: chronic_disease seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: cancer seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: treatment seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: allergy_name seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: chronic_disease seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: cancer seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: treatment seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: allergy_name seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading Fine_Tuned Model","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nclassifier = pipeline(\"ner\", model=\"SKT27182/Name_Entity_Recognizer\")","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:19:55.897188Z","iopub.execute_input":"2024-01-22T18:19:55.897990Z","iopub.status.idle":"2024-01-22T18:19:59.187740Z","shell.execute_reply.started":"2024-01-22T18:19:55.897955Z","shell.execute_reply":"2024-01-22T18:19:59.186610Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/811 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48ee17c14a954907affd2cf65133f53b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e95d717d1cc84bac8ad3a9f457e48783"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2606ce739e5e4c8f81e5deff96fe30a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5751b13bde0f46a5abe38a5926a34d05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a44385b08f254710a997819208ced3bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5f6899058c3424daa234f47bb2b4784"}},"metadata":{}}]},{"cell_type":"code","source":"classifier(\"ust have the diagnosis of NB in accordance with the International Criteria, i.e., either histopathology (confirmed by the MSKCC Department of Pathology) or BM involvement plus elevated urinary catecholamines\")","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:20:00.393958Z","iopub.execute_input":"2024-01-22T18:20:00.394798Z","iopub.status.idle":"2024-01-22T18:20:00.551198Z","shell.execute_reply.started":"2024-01-22T18:20:00.394760Z","shell.execute_reply":"2024-01-22T18:20:00.550316Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[{'entity': 'chronic_disease',\n  'score': 0.67050254,\n  'index': 7,\n  'word': 'n',\n  'start': 26,\n  'end': 27},\n {'entity': 'chronic_disease',\n  'score': 0.7304839,\n  'index': 8,\n  'word': '##b',\n  'start': 27,\n  'end': 28},\n {'entity': 'chronic_disease',\n  'score': 0.7906186,\n  'index': 43,\n  'word': 'ur',\n  'start': 185,\n  'end': 187},\n {'entity': 'chronic_disease',\n  'score': 0.7500598,\n  'index': 44,\n  'word': '##ina',\n  'start': 187,\n  'end': 190},\n {'entity': 'chronic_disease',\n  'score': 0.8246452,\n  'index': 45,\n  'word': '##ry',\n  'start': 190,\n  'end': 192},\n {'entity': 'chronic_disease',\n  'score': 0.7856513,\n  'index': 46,\n  'word': 'cat',\n  'start': 193,\n  'end': 196},\n {'entity': 'chronic_disease',\n  'score': 0.61697036,\n  'index': 47,\n  'word': '##ech',\n  'start': 196,\n  'end': 199},\n {'entity': 'chronic_disease',\n  'score': 0.5686747,\n  'index': 48,\n  'word': '##ola',\n  'start': 199,\n  'end': 202},\n {'entity': 'chronic_disease',\n  'score': 0.5305861,\n  'index': 49,\n  'word': '##mine',\n  'start': 202,\n  'end': 206},\n {'entity': 'chronic_disease',\n  'score': 0.5939671,\n  'index': 50,\n  'word': '##s',\n  'start': 206,\n  'end': 207}]"},"metadata":{}}]},{"cell_type":"markdown","source":"- Above it is assigning entity to each of the tokenized word, which may not be in the exact form as that in the inout text.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}