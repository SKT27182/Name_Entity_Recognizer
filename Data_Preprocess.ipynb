{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\"Continual_Learning/G1.xlsx\", index_col=0)\n",
    "df2 = pd.read_excel(\"Continual_Learning/G2.xlsx\", index_col=0)\n",
    "df3 = pd.read_excel(\"Continual_Learning/G3.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping any rows with NaN values\n",
    "df1 = df1.dropna()\n",
    "df2 = df2.dropna()\n",
    "df3 = df3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8:16:chronic_disease,20:32:treatment</td>\n",
       "      <td>portal fibrosis by liver biopsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22:34:treatment</td>\n",
       "      <td>Contra-indication to liver biopsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,32:44:treatment,,</td>\n",
       "      <td>Have a stable weight since the liver biopsy was performed defined by no more than a 5 % loss of initial body weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26:38:treatment,</td>\n",
       "      <td>Subject agrees to have a liver biopsy performed after 24 weeks of treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,43:55:treatment,</td>\n",
       "      <td>Liver steatosis (on visual estimate or on liver biopsy) &gt; 30%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tags  \\\n",
       "0  8:16:chronic_disease,20:32:treatment   \n",
       "1                       22:34:treatment   \n",
       "2                    ,32:44:treatment,,   \n",
       "3                      26:38:treatment,   \n",
       "4                     ,43:55:treatment,   \n",
       "\n",
       "                                                                                                                  text  \n",
       "0                                                                                      portal fibrosis by liver biopsy  \n",
       "1                                                                                    Contra-indication to liver biopsy  \n",
       "2  Have a stable weight since the liver biopsy was performed defined by no more than a 5 % loss of initial body weight  \n",
       "3                                          Subject agrees to have a liver biopsy performed after 24 weeks of treatment  \n",
       "4                                                        Liver steatosis (on visual estimate or on liver biopsy) > 30%  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[[\"tags\", \"text\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating the following tagging scheme for the NER task:\n",
    "\n",
    "\n",
    "| Entity_name | Token |\n",
    "| --- | --- |\n",
    "| Other | 0 |\n",
    "| treatment | 1 |\n",
    "| chronic_disease | 2 |\n",
    "| cancer | 3 |\n",
    "| allergy_name | 4 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_ids = {\n",
    "    \"treatment\": 1,\n",
    "    \"chronic_disease\": 2,\n",
    "    \"cancer\": 3,\n",
    "    \"allergy_name\": 4,\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_index(txt, word):\n",
    "    pattern = re.compile(r'\\b{}\\b'.format(re.escape(word)))\n",
    "\n",
    "    # Find the index of the element containing the pattern\n",
    "    word_index = next((index for index, element in enumerate(txt) if pattern.search(element)), None)\n",
    "\n",
    "    return word_index\n",
    "\n",
    "def get_ner_tokens(row):\n",
    "\n",
    "    # Few tags have leading and trailing commas, removing them\n",
    "    tag = row.tags.strip(\",\").strip()    # start:end:name, start:end:name, ... (start and end are in character level)\n",
    "\n",
    "    # removing leading and trailing whitespace\n",
    "    txt = row.text\n",
    "\n",
    "\n",
    "    try:\n",
    "        txt = txt.split()\n",
    "    except:\n",
    "        print(tag, txt)\n",
    "        return None, None\n",
    "\n",
    "    \n",
    "\n",
    "    # labeled every word as other\n",
    "    labels = np.zeros(len(txt))\n",
    "\n",
    "    # iterate over all tages and mark them with their token\n",
    "    for t in tag.split(\",\"):\n",
    "        if t == \"\":\n",
    "            continue\n",
    "        start, end, name = t.split(\":\")\n",
    "\n",
    "        # as first character is considered as 1 in the dataset, but in python it is 0\n",
    "        start, end = int(start), int(end)\n",
    "        start -= 1\n",
    "        end -= 1\n",
    "\n",
    "        exact_word = \" \".join(txt)[start:end]\n",
    "\n",
    "        n_exact_words = len(exact_word.split())\n",
    "\n",
    "        # check if word is more than one word, if yes then get the index of the first word and save total number of words\n",
    "        if n_exact_words > 1:\n",
    "\n",
    "            exact_word = exact_word.split()[0]\n",
    "\n",
    "            word_index = find_word_index(txt, exact_word)\n",
    "            # word_index = txt.index(exact_word)\n",
    "            try:\n",
    "                for i in range(word_index+1, word_index+n_exact_words):\n",
    "                    labels[i] = entity_ids[name]\n",
    "            except:\n",
    "                return None, None\n",
    "\n",
    "        else:\n",
    "            \n",
    "\n",
    "            word_index = find_word_index(txt, exact_word)\n",
    "\n",
    "            labels[word_index] = entity_ids[name]\n",
    "\n",
    "\n",
    "    return txt, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"tokens\"], df1[\"labels\"] = zip(*df1.apply(get_ner_tokens, axis=1))\n",
    "df2[\"tokens\"], df2[\"labels\"] = zip(*df2.apply(get_ner_tokens, axis=1))\n",
    "df3[\"tokens\"], df3[\"labels\"] = zip(*df3.apply(get_ner_tokens, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with None values\n",
    "df1.dropna(inplace=True)\n",
    "df2.dropna(inplace=True)\n",
    "df3.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT02105766</td>\n",
       "      <td>8:16:chronic_disease,20:32:treatment</td>\n",
       "      <td>portal fibrosis by liver biopsy</td>\n",
       "      <td>[portal, fibrosis, by, liver, biopsy]</td>\n",
       "      <td>[0.0, 2.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT03008070</td>\n",
       "      <td>22:34:treatment</td>\n",
       "      <td>Contra-indication to liver biopsy</td>\n",
       "      <td>[Contra-indication, to, liver, biopsy]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT03008070</td>\n",
       "      <td>,32:44:treatment,,</td>\n",
       "      <td>Have a stable weight since the liver biopsy was performed defined by no more than a 5 % loss of initial body weight</td>\n",
       "      <td>[Have, a, stable, weight, since, the, liver, biopsy, was, performed, defined, by, no, more, than, a, 5, %, loss, of, initial, body, weight]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT03008070</td>\n",
       "      <td>26:38:treatment,</td>\n",
       "      <td>Subject agrees to have a liver biopsy performed after 24 weeks of treatment</td>\n",
       "      <td>[Subject, agrees, to, have, a, liver, biopsy, performed, after, 24, weeks, of, treatment]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT02515708</td>\n",
       "      <td>,43:55:treatment,</td>\n",
       "      <td>Liver steatosis (on visual estimate or on liver biopsy) &gt; 30%</td>\n",
       "      <td>[Liver, steatosis, (on, visual, estimate, or, on, liver, biopsy), &gt;, 30%]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                  tags  \\\n",
       "0  NCT02105766  8:16:chronic_disease,20:32:treatment   \n",
       "1  NCT03008070                       22:34:treatment   \n",
       "2  NCT03008070                    ,32:44:treatment,,   \n",
       "3  NCT03008070                      26:38:treatment,   \n",
       "4  NCT02515708                     ,43:55:treatment,   \n",
       "\n",
       "                                                                                                                  text  \\\n",
       "0                                                                                      portal fibrosis by liver biopsy   \n",
       "1                                                                                    Contra-indication to liver biopsy   \n",
       "2  Have a stable weight since the liver biopsy was performed defined by no more than a 5 % loss of initial body weight   \n",
       "3                                          Subject agrees to have a liver biopsy performed after 24 weeks of treatment   \n",
       "4                                                        Liver steatosis (on visual estimate or on liver biopsy) > 30%   \n",
       "\n",
       "                                                                                                                                        tokens  \\\n",
       "0                                                                                                        [portal, fibrosis, by, liver, biopsy]   \n",
       "1                                                                                                       [Contra-indication, to, liver, biopsy]   \n",
       "2  [Have, a, stable, weight, since, the, liver, biopsy, was, performed, defined, by, no, more, than, a, 5, %, loss, of, initial, body, weight]   \n",
       "3                                                    [Subject, agrees, to, have, a, liver, biopsy, performed, after, 24, weeks, of, treatment]   \n",
       "4                                                                    [Liver, steatosis, (on, visual, estimate, or, on, liver, biopsy), >, 30%]   \n",
       "\n",
       "                                                                                                                labels  \n",
       "0                                                                                            [0.0, 2.0, 0.0, 0.0, 1.0]  \n",
       "1                                                                                                 [0.0, 0.0, 0.0, 1.0]  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3                                                    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "4                                                              [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"processed_data/G1.csv\", index=False)\n",
    "df2.to_csv(\"processed_data/G2.csv\", index=False)\n",
    "df3.to_csv(\"processed_data/G3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"processed_data/G1.csv\")\n",
    "df2 = pd.read_csv(\"processed_data/G2.csv\")\n",
    "df3 = pd.read_csv(\"processed_data/G3.csv\")\n",
    "\n",
    "# add new feature dataset_id\n",
    "df1[\"dataset_id\"] = 1\n",
    "df2[\"dataset_id\"] = 2\n",
    "df3[\"dataset_id\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = pd.concat([df1, df2, df3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_id\n",
       "1    7314\n",
       "2    6420\n",
       "3    6234\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset.dataset_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data to dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_dataset = {\n",
    "    \"ID\": custom_dataset[\"ID\"],\n",
    "    \"tags\": custom_dataset[\"tags\"],\n",
    "    \"text\": custom_dataset[\"text\"],\n",
    "    \"dataset_id\" : custom_dataset[\"dataset_id\"],\n",
    "    \"input_text\": custom_dataset[\"tokens\"],\n",
    "    \"output_label\": custom_dataset[\"labels\"],\n",
    "}\n",
    "\n",
    "# Create a Hugging Face Dataset object\n",
    "dataset = Dataset.from_dict(huggingface_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d731c942b4b407d8dee384157faeba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/19968 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk(\"custom_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pushing the dataset to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "if 'kaggle_web_client' in sys.modules:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    HUGGINGFACE_API_KEY = user_secrets.get_secret(\"HUGGINGFACE_API_KEY\")\n",
    "elif 'google.colab' in sys.modules:\n",
    "    !pip -q install python-dotenv\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    HUGGINGFACE_API_KEY = os.getenv('HUGGINGFACE_API_KEY')\n",
    "\n",
    "else:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    HUGGINGFACE_API_KEY = os.getenv('HUGGINGFACE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/shailja/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from huggingface_hub import login\n",
    "login(token=HUGGINGFACE_API_KEY, write_permission=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ea8e8fda674f74bc4604da78070cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8748e868324ad9b00218d1f62c21c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d8963d5e044ac2b9bb70a47f7d3c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0159b7ea6340ab8c0b18df65ddadb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"SKT27182/NER\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
